---
title: "`spillR`: Spillover Compensation in Mass Cytometry Data"
author: "Marco Guazzini$^{1}$, Alexander G. Reisach$^{2}$, Sebastian Weichwald$^{3}$, and Christof Seiler$^{1,4}$"
date: "$^1$Department of Advanced Computing Sciences, Maastricht University, The Netherlands \\\n $^2$Université Paris Cité, CNRS, MAP5, F-75006 Paris, France \\\n $^3$Department of Mathematical Sciences, University of Copenhagen, Denmark \\\n $^4$Mathematics Centre Maastricht, Maastricht University, The Netherlands \\\n \\\n `r gsub(' 0', ' ', format(Sys.time(), '%B %d, %Y'))`"
output:
  bookdown::pdf_document2: 
    toc: false
  bookdown::word_document2: 
    toc: false
bibliography: spillr_paper.bib
csl: style.csl
link-citations: true
abstract: |
  Channel interference in mass cytometry can cause spillover and may result in miscounting of protein markers. @catalyst introduce an experimental and computational procedure to estimate and compensate for spillover implemented in their R package `CATALYST`. They assume spillover can be approximated by a spillover matrix that encodes proportions of true counts over total observed counts. They estimate the spillover matrix from experiments with beads. We propose to skip the matrix estimation step and work directly with the full bead distributions. We develop a nonparametric finite mixture model, and use the mixture components to estimate the probability of spillover. We implement this in an R package `spillR` using expectation-maximization to fit the mixture model and logistic regression. We test our procedure on synthetic and real data from `CATALYST`. We find that our method compensates low counts accurately, avoids overcompensating high counts, and preserves correlations between markers that may be biologically meaningful.
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, echo=FALSE, warning=FALSE, message=FALSE}
library(CATALYST)
library(CytoSpill)
library(nnls)
library(flowCore)
library(ggplot2)
library(tibble)
library(dplyr)
library(magrittr)
library(readr)
library(tidyr)
library(cowplot)
library(transport)
library(RColorBrewer)
library(spatstat.geom)
source("compensate.R")
source("compCytof.R")
source("plotDiagnostics.R")
set.seed(23)
```

# Introduction

Mass cytometry makes it possible to count a large number of proteins simultaneously on individual cells [@bandura2009mass; @bendall2011single]. Mass cytometry has less spillover---measurements from one channel overlap less with those of another---than flow cytometry [@sp-c; @novo2013generalized], but spillover is still a problem and affects downstream analyses such as differential testing [@diffcyt; @seiler2021cytoglmm] or dimensionality reduction [@scater]. Reducing spillover by careful design of experiment is possible [@takahashi2017mass], but a purely experimental approach may not be sufficient nor efficient [@lun2017influence].

@catalyst propose a method for addressing spillover by conducting an experiment on beads. This experiment measures spillover by staining each bead with a single type of antibody. The slope of the regression line between target antibody and non-target antibodies represents the spillover proportion between channels. @miao2021ab attempt to solve spillover by fitting a mixture model. Our contribution combines the solutions of @catalyst and @miao2021ab. We still require a bead experiment, as in @catalyst, but estimate spillover leveraging a statistical model, as in @miao2021ab. Both previous versions rely on an estimate for the spillover matrix. The spillover matrix encodes the pairwise spillover proportion between channels. We avoid estimating a spillover matrix and instead model spillover by fitting a mixture model to the observed counts. Our main new assumption is that the spillover distribution---not just the spillover proportion---from the bead experiment carries over to the biological experiment. In other words, we transfer the spillover distribution to the real experiment instead of just the spillover proportion encoded in the spillover matrix.

```{r intro-example, fig.height=3, fig.width=6, out.width="70%", fig.align="center", fig.cap="Two-dimensional histograms of cell counts. The blue shaded rectangle is an estimate of spillover from CD36 (Nd144Di) into CD4 (Nd145Di). Our method masks counts that fall inside this rectangle. Counts are arcsinh transformed with cofactor of five.", echo=FALSE, warning=FALSE, message=FALSE}
# constants
bc_key <- c(139, 141:156, 158:176)

# helper functions
tfm <- function(x) asinh(x/5)
colorscale = scale_fill_gradientn(
  colors = rev(brewer.pal(9, "YlGnBu")),
  values = c(0, exp(seq(-5, 0, length.out = 100)))
  )

# --------- left: experiment with beads ---------

sce_spill <- prepData(ss_exp)
sce_spill <- assignPrelim(sce_spill, bc_key, verbose = FALSE)
sce_spill <- applyCutoffs(estCutoffs(sce_spill))
sce_spill <- computeSpillmat(sce_spill)
counts_spill <- t(assay(sce_spill, "counts"))
counts_spill <- floor(counts_spill)
counts_spill <- as_tibble(counts_spill)

channel_names <- rowData(sce_spill)[,"channel_name"]
names(counts_spill) <- channel_names
counts_spill <- mutate(counts_spill, barcode = sce_spill$bc_id)
counts_spill <- filter(counts_spill, barcode == 144)
counts_spill <- counts_spill %>% select(-barcode)
counts_spill <- mutate(counts_spill, type = "beads for CD36 (Nd144Di)")

# --------- right: experiment with real cells ---------

data(mp_cells, package = "CATALYST")
sce <- prepData(mp_cells)
channel_names <- rowData(sce)[, "channel_name"]
counts_real <- t(assay(sce, "counts"))
counts_real <- floor(counts_real)
colnames(counts_real) <- channel_names
counts_real <- as_tibble(counts_real)
counts_real <- mutate(counts_real, type = "real cells")

# --------- combine tables for plotting ---------
combo <- bind_rows(counts_spill, counts_real)
ggplot(combo, aes(x = tfm(Nd144Di), y = tfm(Nd145Di))) +
  annotate("rect", 
           xmin = 0, xmax = 6.5,
           ymin = 0, ymax = 2.5, 
           alpha = .1, fill = "blue") +
  geom_hex(bins = 32) +
  colorscale +
  facet_wrap(~type) + 
  xlab("CD36 (Nd144Di)") +
  ylab("CD4 (Nd145Di)")
```

To illustrate the main idea of our work, we consider an example with only two markers (Figure \@ref(fig:intro-example)). The left panel depicts an experiment using beads stained only for CD36 (Nd144Di). In this example, the protein CD36 is conjugated with Nd144Di (Nd is the metal and 144 is the number of neutrons of the isotope). Without any spillover, all beads would have zero cell counts for CD4 (ND145Di). Yet, there are many positive CD4 (ND145Di) bead counts. The blue shaded area provides a reasonable estimate of the range of spillover values. The right panel shows an experiment conducted with real cells. Some of the values in the blue shaded area could in principle be real, low counts, but one would expect real counts to be higher and low counts more likely to be due to spillover. While it is not known how many of the low counts are due to spillover, an estimate can be obtained using the bead experiment. We propose to carry over a weighted version of the blue shaded area to the real experiment using finite mixtures. The blue shaded area plays the role of the spillover component and the non-shaded area is the component representing the true marker signal. Our objective is to separate the true signal from the spillover in this mixture. 

This example highlights the main difference between our method and @catalyst. After masking cell marker CD4 (ND145Di) counts that are likely due to spillover, the average of the remaining CD4 (ND145Di) counts will be larger than that of all CD4 (ND145Di) counts. So, in this example, our spillover correction method increases the average count. By contrast, @catalyst will shrink all the counts towards zero. As a consequence, the average count will be lower after correction.

In Section \@ref(methods), we present our mixture model and link it to calculating spillover probabilities for specific count values. Our estimation procedure is based on an EM algorithm and logistic regression, and implemented in our new R package `spillR`^[https://github.com/marcoguazzini/spillR]. In Section \@ref(results), we conduct experiments on simulated and real data obtained from the `CATALYST` R package [@catalyst]. Section \@ref(discussion) discusses our synthetic experiments and relates our findings to `CATALYST`.

# Methods

## Example

```{r method-example, fig.height=3, fig.width=9, out.width="100%", fig.align="center", fig.cap="Left panel: Frequency polygons of marker CD3 (Yb173Di) before and after spillover compensation. Right panel: Density plot of spillover markers. The dashed curve represents the estimated spillover probability with our method. Arcsinh transformed counts with cofactor of five.", echo=FALSE, warning=FALSE, message=FALSE}
# constants
bc_key <- c(139, 141:156, 158:176)

# --------- experiment with beads ---------

sce_bead <- prepData(ss_exp)
sce_bead <- assignPrelim(sce_bead, bc_key, verbose = FALSE)
sce_bead <- applyCutoffs(estCutoffs(sce_bead))
sce_bead <- computeSpillmat(sce_bead)

# --------- experiment with real cells ---------

data(mp_cells, package = "CATALYST")
sce <- prepData(mp_cells)

# --------- table for mapping markers and barcode ---------
marker_to_barc <- 
  rowData(sce_bead)[,c("channel_name", "is_bc")] %>%
  as_tibble %>%
  dplyr::filter(is_bc == TRUE) %>%
  mutate(barcode = bc_key) %>%
  select(marker = channel_name, barcode)

# --------- call compensate from compCytof package ---------
sce_spillr <- compCytof(sce, sce_bead, marker_to_barc, overwrite = FALSE)
p_list <- plotDiagnostics(sce_spillr, "Yb173Di")

plot_grid(
    p_list[[1]] + xlab("CD3 (Yb173Di)"),
    p_list[[2]] + xlab("CD3 (Yb173Di)"),
    rel_widths = c(0.5, 0.5), nrow = 1
  )
```

Figure \@ref(fig:method-example) illustrates our procedure using a dataset from the `CATALYST` package as an example. There are four markers, HLA-DR (Yb171Di), HLA-ABC (Yb172Di), CD8 (Yb174Di), and CD45 (Yb176Di), that spill over into the target marker, CD3 (Yb173Di). The markers have two names: the first name is the protein name and second name in brackets is the conjugated metal. There are bead experiments for each of the spillover markers. The panel on the left displays the distribution of our target marker, CD3 (Yb173Di), before and after spillover correction. Our compensation method masks some counts in the range between zero to four. Larger counts are not affected by the correction, as can be seen by the overlap of both curves. 

The panel on the right depicts the marker distributions from the beads experiment. We see that for this marker the bead experiments are high-quality as the target marker Yb173Di is concentrated around six, similarly to the experiment with real cells. This suggests that the spillover marker values can be transferred to the real experiments. Marker Yb172Di shows large spillover into Yb173Di, and suggests that much of the first mode of the distribution may be attributed to that marker. Spillover results in low counts for the other markers, making it justifiable to set all the low counts to zero.

The dashed black curve is our estimated spillover probability. We can see that at value two on the horizontal axis the probability of spillover is around 0.5. Our correction step assigns around 50% of cells to spillover, and keeps the other 50% at the current value. Counts below a value of one have spillover probability close to one, which means that our procedure assigns most of them to spillover and masks them from the sample. Counts above four stem from spillover with probability 0 (and from the actual target with probability 1), which means that our procedure keeps them at their raw uncorrected value.

## Definition of Spillover Probability and Assumptions

We observe a count $Y_i$ of a target marker in cell $i$. We model the observed $Y_i$ as a finite mixture [@mclachlan2019finite] of unobserved true marker counts $Y_i \mid Z_i = 1$ and spillover markers counts $Y_i \mid Z_i = 2, \dots, Y_i \mid Z_i = K$ with mixing probabilities $\pi_{k} = P(Z_i = k)$ for $k = 1, \dots, K$, 
$$
P(Y_i = y) = \sum_{k = 1}^K \pi_k \, P(Y_i = y \mid Z_i = k).
$$
The first mixing probability is the proportion of true signal in the observed counts. The other $K-1$ mixing probabilities are the proportions of spillover. The total sum of mixing probabilities equals one, $\sum_k \pi_k = 1$. The total number of markers in mass cytometry panels is between 30 and 40 [@bendall2011single], but only a small subset of three to four markers spill over into the target marker [@catalyst]. So, typically $K = 1+3$ or $K = 1+4$.

Experimentally, we only measure a sample from the distribution of $Y_i$. The probabilities $\pi_k$ and true distributions $P(Y_i = y \mid Z_i = k)$ are unobserved, and we need to estimate them from data. In many applications, the mixture components are in a parametric family, for example, the negative binomial distribution. As spillover correction is a pre-processing step followed by downstream analyses, choosing the wrong model can introduce biases in the next analysis step. To mitigate such biases, we propose to fit nonparametric mixture components. We make three assumptions that render the components and mixture probabilities identifiable:

* <div id='assumption1'>(A1) Spillover distributions are the same in bead and real experiments.</div>

The distribution of $Y_i \mid Z_i = k$ for all $k > 1$ is the same in beads and real cells. This assumption allows us to learn the spillover distributions of $Y_i \mid Z_i = k$ for all $k > 1$ from experiments with beads, and transfer them to the experiment with real cells. This assumption relies on high-quality single stained bead experiments that measure spillover in the same range as the target biological experiment.

* <div id='assumption2'>(A2) For each cell $i$, the observed count $Y_i$ can only be due to one distribution.</div>

This assumption is already implied by the statement of the mixture model. It allows us to calculate the spillover probability for a given count $Y_i = y$ from the posterior probability that it arises through spillover from markers $k > 1$,
$$
P(\text{spillover} \mid Y_i = y) = P(Z_i > 1 \mid Y_i = y) = 
1 - P(Z_i = 1 \mid Y_i = y) = 
1 - \frac{\pi_1 \, P(Y_i = y \mid Z_i = 1)}{P(Y_i = y)}.
$$
To parse this calculation, recall that in mixture models the $\pi_1$ is the prior probability, $P(Y_i = y \mid Z_i = 1)$ is the conditional probability given the mixture component, and the denominator is the marginal distribution. Putting all this together and applying Bayes rule leads to the posterior probability.

* <div id='assumption3'>(A3) Spillover probability curves are logistic functions.</div>

The spillover probability is the probability that the counts are not due to the marker of interest but the result of another marker spilling over into $Y_i$. The spillover probability is a function of $y$. Under (A3), smaller $y$ are more likely a result of another marker spilling over whereas sufficiently large $y$ are not due to spillover and only carry the true signal. Although it is biologically possible that spillover results in high counts, this may be considered unlikely and the assumption makes our statistical procedure more stable. We model the spillover probabilities using logistic regression.

## Estimation of Spillover Probability

We propose a two step procedure for estimating the spillover probability. In step 1, we estimate mixture components and mixture probabilities. We refine these estimates using the EM algorithm [@dempster1977maximum]. In step 2, we fit a logistic function to the noisy probability estimates from step 1 using logistic regression. We use smooth probability estimates to assign counts to spillover or signal.

Let's denote the $n \times K$ count matrix as $\mathbf{Y} = (y_{ik})$ with real cells in the first column and beads in columns two and higher. To simplify mathematical notation but without loss of generality, we assume that the number of cells from real and bead experiments have the same $n$. In practice, the number of cells from bead experiments is much smaller than from real experiments. The $k$th column of $\mathbf{Y}$ contains marker counts for the $k$th spillover marker, which represents the empirical spillover distribution of marker $k$ into the target marker, that is, the marker in the first column of $\mathbf{Y}$.

We use the empirical weighted cumulative distribution function (CDF) with non-negative weights $w_i$ at each data point to model the marker distributions $F$ for a specific marker $k$,
$$
\widehat{F}_k(y) = \frac{\sum_{i = 1}^n w_i \, \mathbf{1} \left( y_{ik} \le y \right)}{\sum_{i = 1}^n w_i},
$$
where $\mathbf{1}(\cdot)$ is the indicator function.

### Step 1: EM Algorithm {-}

* Initialization: We set the mixture probability vector to the discrete uniform, 
$$
\hat{\pi}_{k} = 1/K,
$$ 
and evaluate the $k$th mixture component using its empirical CDF with equal weights for all data points,
$$
\widehat{P}(Y_i = y \mid Z_i = k) = \widehat{F}_k(y) - \widehat{F}_k(y-1) \text{ with } w_i = 1/n.
$$

* E-step: We evaluate the posterior probability of a count $y$ belonging to marker $k$,
$$
\widehat{P}\left(Z_i = k \mid Y_i = y \right) = 
\frac
{ \hat{\pi}_k \, \widehat{P}(Y_i = y \mid Z_i = k) }
{ \sum_{k = 1}^K \hat{\pi}_k \, \widehat{P}(Y_i = y \mid Z_i = k) }.
$$

* M-step: We estimate the new mixture probability vector from posterior probabilities, 
$$
\hat{\pi}_k = 
\frac{1}{n} \sum_{i = 1}^n \widehat{P}\left(Z_i = k \mid Y_i = y \right),
$$
and estimate the new target marker distribution using its empirical CDF with weights set to posterior probabilities,
$$
\widehat{P}(Y_i = y \mid Z_i = 1) = \widehat{F}_1(y) - \widehat{F}_1(y-1) \text{ with } w_i = \widehat{P} \left(Z_i = 1 \mid Y_i = y \right).
$$
We keep the bead distributions, $\widehat{P}(Y_i = y \mid Z_i = k)$ for all $k > 1$, fixed at their initial value.

To refine our estimates, we iterate over the E and M-steps until estimates stabilize. The final output is the spillover probability curve with estimates at discrete points in the support of $Y_i$, 
$$
\widehat{P}(\text{spillover} \mid Y_i = y) = 1 - \widehat{P}(Z_i = 1 \mid Y_i = y).
$$

We rely on assumption [(A1)](#assumption1) to justify updating only the distribution of the target marker. We rely on assumption [(A2)](#assumption2) to justify calculating the spillover probability from the mixture model. We refer to Appendix \@ref(em-algorithm-example) for a numerical example of our EM algorithm. 

### Step 2: Logistic Regression {-}

This step is a post-processing step of $\widehat{P}(\text{spillover} \mid Y_i = y)$. Until now, the procedure is fully nonparametric. We apply no regularization to $y$'s that are close to one another. As a result, the spillover probability estimates benefit from regularization using our assumption [(A3)](#assumption3).

The logistic regression model is
$$
\log\left(\frac{\widehat{P}(\text{spillover} \mid Y_i = y)}{1-\widehat{P}(\text{spillover} \mid Y_i = y)}\right) = \beta_0 + \beta_1 y,
$$
with $y$ transformed using the inverse hyperbolic sine (arcsinh) transformation with the cofactor set to five to stabilize the variance and account for heteroskedasticity [@bendall2011single]. We fit the logistic regression model using maximum likelihood (MLE) estimation and obtain estimates for the intercept $\hat{\beta}_0$ and slope $\hat{\beta}_1$. The post-processed spillover probability for $Y_i = y$ is
$$
\widetilde{P}(\text{spillover} \mid Y_i = y) = \left(1 + e^{-(\hat{\beta}_0 + \hat{\beta}_1 y)}\right)^{-1}.
$$
The $\widetilde{P}(\text{spillover} \mid Y_i = y)$ is a smooth version of the noisy estimate from step 1, $\widehat{P}(\text{spillover} \mid Y_i = y)$. We obtain the last equation by solving the logistic regression model for the spillover probability and plugging in the MLE estimate. 

To perform the spillover compensation, we draw from a Bernoulli distribution with the spillover probability as parameter to decide whether or not to assign a given count to spillover. We consider spillover counts as having no clear biological interpretation and mask them from our dataset while keeping all other counts. In our implementation, we choose to set spillover counts to `NA` instead of zero to avoid zero-inflated distributions. 

<!-- 

## Identifiability

[TODO] Need to think if our model assumptions guarantee identifiability and if our procedure is guaranteed to converge. I think if it is identifiable, then convergence follows from the property of the EM algorithm. Some related work [@hall2003nonparametric; @aragam2020identifiability] that might help. 

-->

# Results

We first evaluate our new method `spillR` on simulated datasets. We probe our method to experimentally find its shortcomings. Then, we compare `spillR` to the non-negative least squares method implemented in the R package `CATALYST` on real data from the same package. All experiments and plots can be reproduced by compiling the R markdown file `spillR_paper.Rmd`^[https://github.com/ChristofSeiler/spillR_paper]. In our experiments, performing 10 EM iteration steps are sufficient to reach convergence with initial values set as described in the previous section.

## Simulated Data

```{r simulated-experiments, echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE}
# --------- global parameters ---------

n_real <-10000
n_bead <- 1000
lambda_real <- 100
lambda_bead  <- 70
lambda_bead_high  <- 130
spill_prob   <- 0.1
n_rep <- 5

# --------- helper functions ---------

tfm <- function(x) asinh(x/5)

compute_average <- function(ftn, tau) {
  data <- ftn(tau)
  comp <- compensate(data$df_real, data$df_bead, 
                     target_marker = "Y", 
                     spillover_markers = "Z")
  y_comp  <- comp$tb_compensate$corrected
  y_truth <- data$Z_target

  tibble(
    mean_obsv = mean(data$df_real$Y),
    mean_comp = mean(y_comp, na.rm = TRUE),
    mean_truth = mean(y_truth)
  )
}

# --------- panel (a) ---------

generate_data_a1 <- function(shift) {
  # real experiment
  Z_target <- rpois(n = n_real, lambda = lambda_real)
  Z_spill  <- rpois(n = n_real, lambda = lambda_bead+shift)
  spill    <- rbinom(n = n_real, size = 1, prob = spill_prob)
  Y        <- (1-spill)*Z_target + spill*Z_spill
  df_real  <- tibble(Y = Y, barcode = "Y", type = "real cells")
  
  # bead experiment
  Z_bead   <- rpois(n = n_bead, lambda = lambda_bead)
  df_bead  <- tibble(Y = Z_bead, barcode = "Z", type = "beads")
  
  list(df_real = df_real, df_bead = df_bead, 
       Z_target = Z_target, Z_spill = Z_spill)
}

# create parameter combination
d_a1 <- expand.grid(
  tau = seq(-30, 0, length.out = 30), 
  replicate = 1:n_rep,
  title = "Bead Shift (A1)"
  ) %>%
  rowwise() %>% 
  mutate(unnest(compute_average(generate_data_a1, tau)))

# --------- panel (b) ---------

generate_data_a2 <- function(spill_hidden) {
  # real experiment
  Z_target <- rpois(n = n_real, lambda = lambda_real)
  Z_spill  <- rpois(n = n_real, lambda = lambda_bead)
  Z_spill_hidden <- rpois(n = n_real, lambda = lambda_bead)
  no_spill <- 1 - sum(spill_prob, spill_hidden)
  spill_prob_vec <- c(no_spill, spill_prob, spill_hidden)
  spill    <- rmultinom(n = n_real, size = 1, prob = spill_prob_vec)
  Y        <- spill[1, ]*Z_target + spill[2, ]*Z_spill + spill[3, ]*Z_spill_hidden
  df_real  <- tibble(Y = Y,
                     barcode = "Y",
                     type = "real cells")
  
  # bead experiment
  Z_bead   <- rpois(n = n_bead, lambda = lambda_bead)
  df_bead  <- tibble(Y = Z_bead,
                     barcode = "Z",
                     type = "beads")
  
  list(df_real = df_real, df_bead = df_bead, 
       Z_target = Z_target, Z_spill = Z_spill)
}

# create parameter combination
d_a2 <- expand.grid(
  tau = seq(from = 0, to = 0.1, length.out = 30), 
  replicate = 1:n_rep,
  title = "Model Misspecification (A2)"
  ) %>%
  rowwise() %>% 
  mutate(unnest(compute_average(generate_data_a2, tau)))

# --------- panel (c) ---------

generate_data_a3 <- function(mode_prob) {
  # real experiment
  Z_target  <- rpois(n = n_real, lambda = lambda_real)
  Z_spill1  <- rpois(n = n_real, lambda = lambda_bead)
  Z_spill2  <- rpois(n = n_real, lambda = lambda_bead_high)
  mode      <- rbinom(n = n_real, size = 1, prob = mode_prob)
  Z_spill   <- (1-mode)*Z_spill1 + mode*Z_spill2
  spill     <- rbinom(n = n_real, size = 1, prob = spill_prob)
  Y         <- (1-spill)*Z_target + spill*Z_spill
  df_real   <- tibble(Y = Y, barcode = "Y", type = "real cells")
  
  # bead experiment
  Z_bead1   <- rpois(n = n_real, lambda = lambda_bead)
  Z_bead2   <- rpois(n = n_real, lambda = lambda_bead_high)
  mode      <- rbinom(n = n_real, size = 1, prob = mode_prob)
  Z_bead    <- (1-mode)*Z_bead1 + mode*Z_bead2
  df_bead   <- tibble(Y = Z_bead, barcode = "Z", type = "beads")

  list(df_real = df_real, df_bead = df_bead, 
       Z_target = Z_target, Z_spill = Z_spill)
}

# create parameter combination
d_a3 <- expand.grid(
  tau = seq(from = 0, to = 1, length.out = 30), 
  replicate = 1:n_rep,
  title = "High Count Spillover (A3)"
  ) %>%
  rowwise() %>% 
  mutate(unnest(compute_average(generate_data_a3, tau)))

# --------- combined plot ---------

tb_experiment <- bind_rows(d_a1, d_a2, d_a3)
tb_summary <- tb_experiment %>% 
    group_by(title, tau) %>% 
    summarize(
      uncorrected = mean(mean_obsv),
      signal = mean(mean_truth),
      spillR = mean(mean_comp)
      ) %>% 
    ungroup()

p_overview <- pivot_longer(tb_summary, -c(title, tau), 
             names_to = "mean", values_to = "count") %>%
  mutate(mean = factor(mean, levels = c("signal", "uncorrected", "spillR"))) %>%
  ggplot(aes(tau, count, color = mean)) +
  geom_line() + 
  facet_wrap(~title, scales = "free_x", nrow = 1) +
  scale_color_manual(values = c("#000000", "#E69F00", "#56B4E9"))
```

```{r simulated-experiments-critical-values, echo = FALSE, warning = FALSE, message = FALSE}
generate_critical <- function(fn, tau) {
  data <- fn(tau)
  bind_rows(
    tibble(count = data$Z_target, variable = "signal", type = "truth"),
    tibble(count = data$Z_spill, variable = "spillover", type = "truth"),
    tibble(count = data$df_real$Y, variable = "signal", type = "observed"),
    tibble(count = data$df_bead$Y, variable = "spillover", type = "observed")
    ) %>% 
    mutate(tau = tau) %>%
    mutate(type = factor(type, levels = c("observed", "truth")))
}

df_a1 <- lapply(
  c(-30, -15, 0), 
  function(x) generate_critical(generate_data_a1, x)
  ) %>% 
  bind_rows() %>% 
  mutate(title = "Bead Shift (A1)")

df_a2 <- lapply(
  c(0, 0.05, 0.1), 
  function(x) 
    generate_critical(generate_data_a2, x)
  ) %>% 
  bind_rows() %>%
  mutate(title = "Model Misspecification (A2)")

df_a3 <- lapply(
  c(0, 0.5, 1.0), 
  function(x) 
    generate_critical(generate_data_a3, x)
  ) %>% 
  bind_rows() %>%
  mutate(title = "High Count Spillover (A3)")

df <- bind_rows(df_a1, df_a2, df_a3) %>%
  mutate(title = factor(
    title, levels = c(
      "Bead Shift (A1)", 
      "Model Misspecification (A2)", 
      "High Count Spillover (A3)"
    ))) %>%
  mutate(tau = factor(tau, levels = c(0, 0.05, 0.1, 0.5, 1, -15, -30)))

p_critical <- ggplot(df, aes(count, color = variable, linetype = type)) + 
  geom_density(key_glyph = "path") + 
  facet_wrap(~title + tau, dir = "v") +
  scale_color_manual(values = c("#000000", "#009E73"))
```

```{r simulated-experiments-plot, fig.height = 7, fig.width = 9, out.width = "90%", fig.align = "center", echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Three experiments testing our three assumptions (A1), (A2), and (A3). Top row: mean values over the entire range of the experimental setups. Rows two to four: density plots for three parameter settings to illustrate the generated distributions."}
plot_grid(p_overview, p_critical, 
          ncol = 1, rel_heights = c(0.3, 0.7), align = "v")
```

We choose three different experiments to test how robust `spillR` is when one of our three assumptions are violated. We explore a wide range of possible parameter settings. Figure \@ref(fig:simulated-experiments-plot) has three columns, each representing one experimental setup. The first column tests our assumptions [(A1)](#assumption1), the second [(A2)](#assumption2), and the third [(A3)](#assumption3). For all three experiments, we model counts using a Poisson distribution with parameter $\lambda$. We simulate 10,000 real cells with $\lambda = 100$, 1,000 beads with $\lambda = 70$, and spillover probability of $0.1$. Beads are an independent copy of the true spillover. The other parameters and statistical dependencies are specific to each experiment. The details of the generative models are given in Appendix \@ref(generative-models). We repeat each simulation five times and report averages over the five replications. Figure \@ref(fig:simulated-experiments-plot) has four rows. The first row represents the summary of the means for each experimental setup as a function of their respective parameter $\tau$. This parameter has a different meaning in each setup. To visualize the different experiments, we summarize the full distributions with the true simulated signal mean (black), the uncorrected mean (orange), and the `spillR` corrected mean (blue). Rows two to four illustrate the simulated data distributions for three parameter settings. The solid curves are what we can measure with experiments and the dashed curves are the true but unmeasured signal. We know the signal here because we simulate this data ourselves with the models in Appendix \@ref(generative-models).

<!--
### Bead Shift (A1)
-->

In the first experiment (column one), we shift the measured beads spillover away from the true bead spillover to probe [(A1)](#assumption1). We test a wide range of bead shifts from $\tau = -30$ to no shift at $\tau = 0$. We illustrate this shift in the density plots in row two to four, where the dashed green curve is the true but unobserved density and the solid green curve is the shifted observed density. At $\tau = -30$, the true spillover distribution is well separated from the actual observed spillover. Such low-quality beads cause both the observed and compensated mean to be below the true mean. As the the beads quality improves, the compensated signal move closer to the true mean.

<!--
### Model Misspecification (A2)
-->

In the second experiment (column two), we add a hidden spillover marker to explore the robustness of our method with respect to our second assumption [(A2)](#assumption2). One way to think about this is that the hidden spillover is a form of model misspecification. Our mixture model is undercomplete, which means that there are more true mixture components than we observe in the beads experiment. If $\tau = 0$, then assumption [(A2)](#assumption2) is correct. Large $\tau$ violate our assumption. At $\tau = 0.1$, the hidden spillover is as large as the measured spillover. The compensated means are closer to the true means across the test range. The observed mean diverges from the true mean with increasing $\tau$ due to the transfer of mass from the signal to the spillover distribution.

<!--
### High Count Spillover (A3)
-->

In the third experiment (column three), we model spillover with a bimodal distribution. Here $\tau$ is the mixing probability of the two modes. The locations of the two spillover modes are fixed. If $\tau = 0$, then our assumption [(A3)](#assumption3) is correct. If $\tau = 0.5$, the first mode of the bimodal beads distribution is left to the signal mode, and the second mode is to the right. This setup violates [(A3)](#assumption3) as the true spillover curve is not monotonically increasing or decreasing. If $\tau = 1$, then [(A3)](#assumption3) holds. The corrected mean is stable across the test range. The uncorrected mean is sensitive to changes in $\tau$, resulting in under or over-estimated mean values.

## Real Data

```{r spillr-vignette, fig.height = 6, fig.width = 10, out.width = "100%", fig.align = "center", echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Comparison of compensation methods and uncorrected counts on real data. Counts are arcsinh transformed with cofactor of five."}
 # constants
bc_key <- c(139, 141:156, 158:176)

# helper functions
colorscale = scale_fill_gradientn(
  colors = rev(brewer.pal(9, "YlGnBu")),
  values = c(0, exp(seq(-5, 0, length.out = 100)))
  )

# --------- experiment with beads ---------

sce_bead <- prepData(ss_exp)
sce_bead <- assignPrelim(sce_bead, bc_key, verbose = FALSE)
sce_bead <- applyCutoffs(estCutoffs(sce_bead))
sce_bead <- computeSpillmat(sce_bead)

# --------- experiment with real cells ---------

data(mp_cells, package = "CATALYST")
sce <- prepData(mp_cells)

# --------- table for mapping markers and barcode ---------
marker_to_barc <- 
  rowData(sce_bead)[,c("channel_name", "is_bc")] %>%
  as_tibble %>%
  dplyr::filter(is_bc == TRUE) %>%
  mutate(barcode = bc_key) %>%
  dplyr::select(marker = channel_name, barcode)

# --------- call compensate from compCytof package ---------
sce_spillr <- compCytof(sce, sce_bead, marker_to_barc, overwrite = FALSE)

# --------- 2d histogram from spillR (for vignette, not for paper) ---------
# as <- c("counts", "exprs", "compcounts", "compexprs")
# chs <- c( "Yb171Di", "Yb173Di")
# ps <- lapply(as, function(a) 
#     plotScatter(sce_spillr, chs, assay = a))
# plot_grid(plotlist = ps, nrow = 2)

# --------- run CATALYST ---------
sm <- metadata(sce_bead)$spillover_matrix
sce_catalyst <- CATALYST::compCytof(sce, sm, overwrite = FALSE)

# --------- compare spillR and CATALYST (Figure 3B) ---------
exprs_spillr <- sce_spillr %>% 
  assay("exprs") %>%
  t() %>%
  as_tibble() %>%
  mutate(method = "uncorrected")
compexprs_spillr <- sce_spillr %>% 
  assay("compexprs") %>%
  t() %>%
  as_tibble() %>%
  mutate(method = "spillR")
compexprs_catalyst <- sce_catalyst %>% 
  assay("compexprs") %>%
  t() %>%
  as_tibble() %>%
  mutate(method = "CATALYST")
combo <- bind_rows(exprs_spillr, compexprs_spillr, compexprs_catalyst)
combo$method <- factor(combo$method, levels=c('uncorrected', 'CATALYST', 'spillR'))

# row 1
p1 <- ggplot(combo, aes(x = CD3.2, y = CD8b)) +
  geom_hex(bins = 32) + colorscale + facet_wrap(~method) +
  xlab("CD3 (Yb173Di)") + ylab("CD8 (Yb174Di)")
p2 <- ggplot(combo, aes(x = CD3.2, y = CD8)) +
  geom_hex(bins = 32) + colorscale + facet_wrap(~method) +
  xlab("CD3 (Yb173Di)") + ylab("CD8 (La139Di)")

# row 2
p3 <- ggplot(combo, aes(x = HLA.ABC, y = CD3.2)) +
  geom_hex(bins = 32) + colorscale + facet_wrap(~method) +
  xlab("HLA-ABC (Yb172Di)") + ylab("CD3 (Yb173Di)")
p4 <- ggplot(combo, aes(x = HLA.ABC, y = CD3.1)) +
  geom_hex(bins = 32) + colorscale + facet_wrap(~method) +
  xlab("HLA-ABC (Yb172Di)") + ylab("CD3 (Sm147Di)")

# row 3
p5 <- ggplot(combo, aes(x = HLA.ABC, y = HLA.DR.1)) +
  geom_hex(bins = 32) + colorscale + facet_wrap(~method) +
  xlab("HLA-ABC (Yb172Di)") + ylab("HLA-DR (Yb171Di)")
p6 <- ggplot(combo, aes(x = HLA.ABC, y = HLA.DR.2)) +
  geom_hex(bins = 32) + colorscale + facet_wrap(~method) +
  xlab("HLA-ABC (Yb172Di)") + ylab("HLA-DR (Lu175Di)")

plot_grid(p1, p2, p3, p4, p5, p6, ncol = 2)
```

We compare our method to `CATALYST` on one of the example datasets in the `CATALYST` package. The dataset has an experiment with real cells and a corresponding bead experiment. The experiment on real cells has 5,000 peripheral blood mononuclear cells from healthy donors measured on 39 channels. The experiment on beads has 10,000 cells measured on 36 channels. They have single stained bead experiments. The number of beads per mental label range from 112 to 241.

We compare the two methods on the same markers as in the original `CATALYST` paper [@catalyst] in their Figure 3B. In the original experiment, they conjugated three proteins---CD3, CD8, and HLA-DR---with two different metal labels. They conjugated CD8 (first row in Figure \@ref(fig:spillr-vignette)) with Yb174Di (Yb is the metal and 174 is the number of neutrons of the isotope) and La139Di, and similarly for the other rows. On the horizontal axis, we plot the same markers as in the original paper, CD3 and HLA-ABC (for the second and third row). We visualize the joint distributions using two-dimensional histograms.

In all six panels, we observed that `spillR` compensates most strongly in the low counts. In panel CD3 (Yb173Di) against HLA-ABC (Yb172Di), `CATALYST` can be seen to compensate strongly in the middle range. It removes the spherical pattern that shows correlation between the two markers. `spillR` preserves this correlation structure and only masks out the lower counts of CD3 (Yb173Di). This highlights a key difference between `spillR` and `CATALYST`. `spillR` does not correct all counts by shrinking them, but rather removes some counts, following the idea that the distribution of the remaining counts is close to the true distribution. `CATALYST` follows another strategy by shrinking counts across the entire range.

The color code of the two-dimensional histograms indicates the absolute number of cells that fall into one hexagon bin. The uncorrected and `spillR` corrected histograms can contain different absolute number of cells because of `spillR` rounding. To convert mass cytometry data to count data, we convert the raw values to the next lower integer. The uncorrected counts do not undergo this pre-processing step.

# Discussion

The experiment for [(A1)](#assumption1) shows that the mean count after `spillR` correction is closer to the true mean over a wide range of bead shifts. This indicates that our method can perform well even if the bead experiments are imperfect. The experiment for [(A2)](#assumption2) shows that our method is also robust to model misspecification. Additionally, misspecification can be addressed by adding all channels if necessary. The increase in computational cost when adding channels is relatively minor as our method scales linearly in the number of spillover markers. The experiment for [(A3)](#assumption3) shows that the mean count after correction is still closer to the true mean even with a clear violation of this assumption. This result corroborates the usefulness and robustness of our parametric assumption on the spillover probability.

In our comparison to `CATALYST` on real data, we observe the effect of the two different correction strategies. `CATALYST` essentially shrinks counts towards zero by minimizing a non-negative least squares objective. It assumes that spillover is linear up to counts of 5,000. The applied shrinkage is the same for low counts (e.g., below 10) and high counts (e.g., more than 100). By contrast, `spillR` does not require linearity of the spillover, but assumes that the distribution on the beads experiment carries over to the real cells experiment. If counts are in the spillover range (which mostly applies to low counts), they are corrected strongly by masking. If counts are not in the spillover range, then they are left unchanged. Despite the masking, correlations between markers are preserved. The marker correlation between HLA-ABC (Yb172Di) and CD3 (Yb173Di) illustrates this point. `CATALYST` removes the positive correlation, whereas `spillR` keeps the correlation for the higher counts. Compensation methods should try to remove spillover while keeping biological meaningful signal for unbiased downstream analyses. Another advantage of our method is the diagnostic plot of the spillover probability curve. We can judge if the curve makes sense by comparing it to the observed count and bead distributions. Methods based on non-negative least squares are harder to diagnose as they minimize a cost function with no clear biological interpretation.

Reducing the noise of the estimated marker count distributions may be a promising extension of our method. `spillR` estimates bead and cell marker count distributions using the observations from bead experiments. In histograms we observe that these estimates are noisy. Post-processing methods such as polynomial Poisson regression, smoothing, or local polynomial regression may be able to improve the estimates. For the data used in our empirical analysis (with sample sizes of around 100 for the bead experiments) these methods are unstable, but bead experiments with larger sample sizes may allow leveraging such an approach.

# Acknowledgments {-}

We thank EuroBioC2022 for awarding Marco Guazzini a travel award to present a preliminary version of `spillR` in Heidelberg.

# References {-}

<div id="refs"></div>

\newpage

# (APPENDIX) Supplementary Material {-}

# EM Algorithm Example

Here we illustrate the procedure using a numerical example that includes one target and one spillover marker. We have one data matrix $\mathbf{Y}$ that contains real cell counts recorded for marker 1 (column 1) and the bead counts for marker 1 when the true marker was marker 2 (column 2). In practice, $\mathbf{Y}$ is usually a matrix with more than two columns representing multiple spillover markers. The index $i$ is a specific cell in beads and real cells experiment, respectively. Let's assume the following counts,
$$
\mathbf{Y} = (y_{ij}) = 
\begin{bmatrix}
3 & 2 \\ 
5 & 3 \\ 
17 & 2 \\ 
3   \\ 
17 \\ 
2 
\end{bmatrix}.
$$

```{r}
target    <- c(3, 5, 17,  3,  17, 2)
spillover <- c(2, 3,  2, NA, NA, NA)
Y = dplyr::bind_cols(target = target, spillover = spillover)
Y
```

* Initialization: We initialize our EM algorithm by estimating the conditional probability of observing $y$ given that it belongs to the target marker, and another conditional probability given that it belongs to the spillover marker,
$$
\begin{aligned}
& \widehat{P}(Y_i = 2 \mid Z_i = 1)  =  1/6 \qquad & \widehat{P}(Y_i = 2 \mid Z_i = 2) = 2/3 \\
& \widehat{P}(Y_i = 3 \mid Z_i = 1)  =  2/6 \qquad & \widehat{P}(Y_i = 3 \mid Z_i = 2) = 1/3 \\
& \widehat{P}(Y_i = 5 \mid Z_i = 1)  =  1/6 \\
& \widehat{P}(Y_i = 17 \mid Z_i = 1) =  2/6.
\end{aligned}
$$

```{r fig.height=4, fig.width=8, out.width="70%", fig.align="center"}
n1 <- sum(!is.na(Y$target))
n2 <- sum(!is.na(Y$spillover))
F1 <- spatstat.geom::ewcdf(Y$target,    weights = rep(1/n1, n1))
F2 <- spatstat.geom::ewcdf(Y$spillover, weights = rep(1/n2, n2))
par(mfrow = c(1, 2))
plot(F1, main = "CDF of Target",    xlab = "y", ylab = "F1(y)")
plot(F2, main = "CDF of Spillover", xlab = "y", ylab = "F2(y)")
P_Y1 <- c(F1(2)-F1(1), F1(3)-F1(2), F1(5)-F1(4), F1(17)-F1(16))
P_Y2 <- c(F2(2)-F2(1), F2(3)-F2(2), F2(5)-F2(4), F2(17)-F2(16))
P_YZ <- dplyr::bind_cols(P_Y1 = P_Y1, P_Y2 = P_Y2)
P_YZ
```

We initialize the mixture probabilities with the discrete uniform, 
$$
\hat{\pi}_1 = 1/2 \qquad \hat{\pi}_2 = 1/2.
$$ 

```{r}
pi <- c(1/2, 1/2)
```

Now, we update these initial values using the E and M-steps.

* E-step: Calculate the posterior probability for the true marker, and the spillover marker,
$$
\begin{aligned}
& \widehat{P}(Z_i = 1 \mid Y_i = 2)  = \frac{1/2 \cdot 1/6}{1/2 \cdot 1/6 + 1/2 \cdot 2/3} = 1/5 \qquad & \widehat{P}(Z_i = 2 \mid Y_i = 2) = 1 - 1/5 = 4/5 \\
& \widehat{P}(Z_i = 1 \mid Y_i = 3)  = \frac{1/2 \cdot 2/6}{1/2 \cdot 2/6 + 1/2 \cdot 1/3} = 1/2 \qquad & \widehat{P}(Z_i = 2 \mid Y_i = 3) = 1 - 1/2 = 1/2 \\
& \widehat{P}(Z_i = 1 \mid Y_i = 5)  = 1 \\
& \widehat{P}(Z_i = 1 \mid Y_i = 17) = 1.
\end{aligned}
$$

```{r}
P_ZY <- dplyr::mutate(P_YZ, 
                      P_Y1 = pi[1] * P_Y1, 
                      P_Y2 = pi[2] * P_Y2)
P_ZY <- P_ZY / rowSums(P_ZY)
P_ZY <- dplyr::mutate(P_ZY, target = c(2, 3, 5, 17), .before = 1)
P_ZY
```

* M-step: Update the mixing probability vector,
$$
\hat{\pi}_1 = \frac{1/2 + 1 + 1 + 1/2 + 1 + 1/5}{6} = 7/10 \qquad \hat{\pi}_2 = 1 - \hat{\pi}_1 = 3/10,
$$

```{r}
n <- nrow(Y)
YP <- dplyr::left_join(Y, P_ZY, by = "target")
YP
pi <- c(sum(YP$P_Y1)/n, sum(YP$P_Y2)/n)
pi
```

and re-estimate the distribution for the target marker using the posterior probabilities as weights, keep the non-target marker at its initial value, 
$$
\begin{aligned}
& \widehat{P}(Y_i = 2 \mid Z_i = 1)  =  0.0476 \qquad & \widehat{P}(Y_i = 2 \mid Z_i = 2) =  2/3 \\
& \widehat{P}(Y_i = 3 \mid Z_i = 1)  =  0.238 & \widehat{P}(Y_i = 3 \mid Z_i = 2) = 1/3 \\
& \widehat{P}(Y_i = 5 \mid Z_i = 1)  =  0.238 & \\
& \widehat{P}(Y_i = 17 \mid Z_i = 1) =  0.476 &
\end{aligned}
$$

```{r fig.height=4, fig.width=8, out.width="70%", fig.align="center"}
F1 <- spatstat.geom::ewcdf(Y$target, weights = YP$P_Y1)
par(mfrow = c(1, 2))
plot(F1, main = "New CDF of Target",    xlab = "y", ylab = "F1(y)")
plot(F2, main = "CDF of Spillover", xlab = "y", ylab = "F2(y)")
P_Y1 <- c(F1(2)-F1(1), F1(3)-F1(2), F1(5)-F1(4), F1(17)-F1(16))
P_YZ <- bind_cols(P_Y1 = P_Y1, P_Y2 = P_Y2)
P_YZ
```

and calculate the spillover probability estimate,
$$
\begin{aligned}
& \widehat{P}(\text{spillover} \mid Y_i = 2) = 1 - \frac{7/10 \cdot 0.0476}{7/10 \cdot 0.0476 + 3/10 \cdot 2/3} = 0.857 \\
& \widehat{P}(\text{spillover} \mid Y_i = 3) = 1 - \frac{7/10 \cdot 0.238}{7/10 \cdot 0.238 + 3/10 \cdot 1/3} = 0.375 \\
& \widehat{P}(\text{spillover} \mid Y_i = 5) = 0 \\
& \widehat{P}(\text{spillover} \mid Y_i = 17) = 0.
\end{aligned}
$$

```{r}
P_ZY <- dplyr::mutate(P_YZ, 
                      P_Y1 = pi[1] * P_Y1, 
                      P_Y2 = pi[2] * P_Y2)
P_ZY <- P_ZY / rowSums(P_ZY)
P_ZY |>
  dplyr::mutate(target = c(2, 3, 5, 17)) |> 
  dplyr::mutate(p_spillover = 1 - P_Y1) |> 
  dplyr::select(target, p_spillover)
```

This is the result after one iteration.

# Generative Models

## Bead Shift (A1) {-}

Generative model for real cells $Y$ of this experiment:
$$
\begin{aligned}
S              & \sim \text{Bernoulli}(0.1)   & \\
Z              & = S + 1                      & \qquad \text{(pick spillover)} \\
(Y \mid Z = 1) & \sim \text{Poisson}(100)     & \qquad \text{(true signal)} \\
(Y \mid Z = 2) & \sim \text{Poisson}(70+\tau) & \qquad \text{(spillover with shift } \tau \text{)}.
\end{aligned}
$$
The generative model for beads is an independent copy of the unshifted $Y \mid Z = 2$ at $\tau = 0$.

## Model Misspecification (A2) {-}

Generative model for real cells $Y$ of this experiment:
$$
\begin{aligned}
Z              & \sim \text{Categorical}(1 - (0.1 + \tau), 0.1, \tau) & \qquad \text{(pick spillover with probability } \tau \text{)} \\
(Y \mid Z = 1) & \sim \text{Poisson}(100)                             & \qquad \text{(true signal)} \\
(Y \mid Z = 2) & \sim \text{Poisson}(70)                              & \qquad \text{(spillover)} \\
(Y \mid Z = 3) & \sim \text{Poisson}(70)                              & \qquad \text{(hidden spillover)}. \\
\end{aligned}
$$
The generative model for beads is an independent copy of $Y \mid Z > 1$.

## High Count Spillover (A3) {-}

Generative model for real cells $Y$ of this experiment:
$$
\begin{aligned}
S                & \sim \text{Bernoulli}(0.1)  & \\
Z                & = S + 1                     & \qquad \text{(pick spillover)} \\
(Y \mid Z = 1)   & \sim \text{Poisson}(100)    & \qquad \text{(true signal)} \\
H                & \sim \text{Bernoulli}(\tau) & \qquad \text{(pick mode with probability } \tau \text{)} \\
(S \mid H = 0)   & \sim \text{Poisson}(70)     & \qquad \text{(spillover)} \\
(S \mid H = 1)   & \sim \text{Poisson}(130)    & \qquad \text{(high count spillover)} \\
( Y \mid Z = 2)  & \overset{d}{=} S            & \qquad \text{(spillover)}.
\end{aligned}
$$
We use $\overset{d}{=}$ to denote that both random variables follow the same distribution. The random variable $S$ is the marginal distribution of the bimodal spillover distribution with high counts. The generative model for beads is an independent copy of $Y \mid Z = 2$.
