% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\usepackage{euflag}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={spillR: Spillover Compensation in Mass Cytometry Data},
  pdfauthor={Marco Guazzini\^{}\{1\}, Alexander G. Reisach\^{}\{2\}, Sebastian Weichwald\^{}\{3\}, and Christof Seiler\^{}\{1,4,5\}},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{\texttt{spillR}: Spillover Compensation in Mass Cytometry Data}
\author{Marco Guazzini\(^{1}\), Alexander G. Reisach\(^{2}\), Sebastian Weichwald\(^{3}\), and Christof Seiler\(^{1,4,5}\)}
\date{\(^1\)Department of Advanced Computing Sciences, Maastricht University, The Netherlands\\
\(^2\)Université Paris Cité, CNRS, MAP5, F-75006 Paris, France\\
\(^3\)Department of Mathematical Sciences, University of Copenhagen, Denmark\\
\(^4\)Mathematics Centre Maastricht, Maastricht University, The Netherlands\\
\(^5\)Center of Experimental Rheumatology, Department of Rheumatology,\\
University Hospital Zurich, University of Zurich, Switzerland\\
\strut \\
March 16, 2024}

\begin{document}
\maketitle
\begin{abstract}
Channel interference in mass cytometry can cause spillover and may result in miscounting of protein markers. Chevrier \emph{et al.} (\citeproc{ref-catalyst}{2018}) introduce an experimental and computational procedure to estimate and compensate for spillover implemented in their R package \texttt{CATALYST}. They assume spillover can be described by a spillover matrix that encodes the ratio between unstained and stained channels. They estimate the spillover matrix from experiments with beads. We propose to skip the matrix estimation step and work directly with the full bead distributions. We develop a nonparametric finite mixture model and use the mixture components to estimate the probability of spillover. Spillover correction is often a pre-processing step followed by downstream analyses, and choosing a flexible model reduces the chance of introducing biases that can propagate downstream. We implement our method in an R package \texttt{spillR} using expectation-maximization to fit the mixture model. We test our method on synthetic and real data from \texttt{CATALYST}. We find that our method compensates low counts accurately, does not introduce negative counts, avoids overcompensating high counts, and preserves correlations between markers that may be biologically meaningful.
\end{abstract}

\section{Introduction}\label{introduction}

Mass cytometry makes it possible to count a large number of proteins simultaneously on individual cells (\citeproc{ref-bandura2009mass}{Bandura \emph{et al.}, 2009}; \citeproc{ref-bendall2011single}{Bendall \emph{et al.}, 2011}). Although mass cytometry has less spillover---measurements from one channel overlap less with those of another---than flow cytometry (\citeproc{ref-sp-c}{Bagwell and Adams, 1993}; \citeproc{ref-novo2013generalized}{Novo \emph{et al.}, 2013}), spillover is still a problem and affects downstream analyses such as differential testing (\citeproc{ref-diffcyt}{Weber \emph{et al.}, 2019}; \citeproc{ref-seiler2021cytoglmm}{Seiler \emph{et al.}, 2021}) or dimensionality reduction (\citeproc{ref-scater}{McCarthy \emph{et al.}, 2017}). Reducing spillover by careful design of experiment is possible (\citeproc{ref-takahashi2017mass}{Takahashi \emph{et al.}, 2017}), but a purely experimental approach may be neither efficient nor sufficient (\citeproc{ref-lun2017influence}{Lun \emph{et al.}, 2017}).

Chevrier \emph{et al.} (\citeproc{ref-catalyst}{2018}) propose a method for addressing spillover by conducting an experiment on beads. This experiment measures spillover by staining each bead with a single type of antibody. The slope of the regression line between target antibodies and non-target antibodies represents the spillover proportion between channels. Miao \emph{et al.} (\citeproc{ref-miao2021ab}{2021}) attempt to solve spillover by fitting a mixture model. Our contribution combines the solutions of Chevrier \emph{et al.} (\citeproc{ref-catalyst}{2018}) and Miao \emph{et al.} (\citeproc{ref-miao2021ab}{2021}). We still require a bead experiment, as in Chevrier \emph{et al.} (\citeproc{ref-catalyst}{2018}), but estimate spillover leveraging a statistical model, as in Miao \emph{et al.} (\citeproc{ref-miao2021ab}{2021}). Both previous versions rely on an estimate for the spillover matrix. The spillover matrix encodes the pairwise spillover proportion between channels. We avoid estimating a spillover matrix and instead model spillover by fitting a mixture model to the observed counts. Our main new assumption is that the spillover distribution---not just the spillover proportion---from the bead experiment carries over to the biological experiment. In other words, we transfer the spillover distribution to the real experiment instead of just the spillover proportion encoded in the spillover matrix.

We present our mixture model and link it to calculating spillover probabilities for specific count values in Section \ref{methods}. Our estimation procedure is based on an EM algorithm and logistic regression, and implemented in our new R package \texttt{spillR}\footnote{\textcolor{red}{https://bioconductor.org/packages/spillR}}. We conduct experiments on simulated, \textcolor{red}{semi-simulated}, and real data obtained from the \texttt{CATALYST} R package (\citeproc{ref-catalyst}{Chevrier \emph{et al.}, 2018}) in Section \ref{results}, and discuss our experiments and relate our findings to \texttt{CATALYST} in Section \ref{discussion}.

\section{Methods}\label{methods}

\textcolor{red}{
In this section we first illustrate our method \texttt{spillR} (as well as a simple baseline version \texttt{spillR (naive)} by an example, and then describe the algorithm as well as its underlying assumptions. Regarding the terminology, note that in mass cytometry, counts are often referred to as dual counts or signal intensity. We call them counts to emphasize that we rely on the fact that they are non-negative integers as opposed to possibly real valued intensities. 
}

\subsection{Example}\label{example}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{spillr_paper_files/figure-latex/method-example-1} 

}

\caption{\textcolor{red}{Panel A shows a density plot of target and spillover markers, Panel B shows spillover probability for Yb173Di estimated by \texttt{spillR}, and Panel C compares spillover compensation by our methods and \texttt{CATALYST}. Counts are arcsinh transformed with cofactor of five (\protect\hyperlink{ref-bendall2011single}{Bendall \emph{et al.}, 2011}), zero counts are not shown; they are 31 for no compensation, 1603 for \texttt{spillR}, 2162 for \texttt{CATALYST}, and 2 nbins for \texttt{spillR (naive)}. As shown in Panel C, our baseline method \texttt{spillR (naive)} performs similarly to \texttt{CATALYST} and removes the first peak of the uncorrected data (red) between about 2 and 4. By contrast, \texttt{spillR} is sensitive to the difference in shape between the peaks in the bead data (Panel A) the first peak in the real data (Panec C red), and only removes the part that corresponds to a peak in the bead experiment.}}\label{fig:method-example}
\end{figure}

Our procedure is illustrated in Figure \ref{fig:method-example}, using a dataset from the \texttt{CATALYST} package as an example. There are four markers, HLA-DR (Yb171Di), HLA-ABC (Yb172Di), CD8 (Yb174Di), and CD45 (Yb176Di), that spill over into the target marker, CD3 (Yb173Di). The markers have two names: the first name is the protein name and the second name in brackets is the conjugated metal. There are bead experiments for each of the spillover markers.

Panel A depicts the marker distributions from the beads experiment. We see that for this marker the bead experiments are high-quality as the target marker Yb173Di is concentrated around six, similarly to the experiment with real cells. This suggests that the spillover marker values can be transferred to the real experiments. Marker Yb172Di shows large spillover into Yb173Di, and suggests that the left tail of the first mode of the distribution may be attributed to that marker. The other spillover markers have low counts, making it justifiable to set some or all the low counts to zero.

\textcolor{red}{Panel B shows a curve representing our spillover probability estimates. We can see that the probability of spillover is highest at points that correspond to a high density of spillover markers in Panel A. If the spillover probability is close to one, our correction step assigns most cells to spillover.} Counts above four stem from spillover with probability zero (and from the actual target with probability one), which means that our procedure keeps them at their raw uncorrected value.

Panel C displays the distribution of our target marker, CD3 (Yb173Di) before and after spillover correction. \textcolor{red}{We observe few real counts (red) below a value of $2$, so although all methods perform strong compensation in this range, there is little visible change. From $2$ onward there is a clear distinction between the methods. `CATALYST`, like our baseline `spillR (naive)`, compensates nearly all counts below the second peak of the raw counts (red) as spillover. By contrast, `spillR` compensates only where the relative frequency of the raw counts (red) match the density of spillovermarkers in the bead experiment shown in panel A, and does not remove a part of the first peak as a result. While `CATALYST` shifts the distribution of large counts (around 6) slightly to the left, our methods leave them unaffected as the bead experiment shows no spillover in this region.}
\textcolor{red}{
Our baseline method \texttt{spillR (naive)} is similar to \texttt{CATALYST} in low and medium range, but keeps higher counts unchanged.
}

\subsection{Definition of Spillover Probability and Assumptions}\label{definition-of-spillover-probability-and-assumptions}

We observe a count \(Y_i\) of a target marker in cell \(i\). We model the observed \(Y_i\) as a finite mixture (\citeproc{ref-mclachlan2019finite}{McLachlan \emph{et al.}, 2019}) of unobserved true marker counts \(Y_i \mid Z_i = 1\) and spillover marker counts \(Y_i \mid Z_i = 2, \dots, Y_i \mid Z_i = K\) with mixing probabilities \(\pi_{k} = P(Z_i = k)\) for \(k = 1, \dots, K\),
\[
P(Y_i = y) = \sum_{k = 1}^K \pi_k \, P(Y_i = y \mid Z_i = k).
\]
The first mixing probability is the proportion of true signal in the observed counts. The other \(K-1\) mixing probabilities are the proportions of spillover. The total sum of mixing probabilities equals one, \(\sum_k \pi_k = 1\). The total number of markers in mass cytometry panels is between 30 and 40 (\citeproc{ref-bendall2011single}{Bendall \emph{et al.}, 2011}), but only a small subset of three to four markers spill over into the target marker (\citeproc{ref-catalyst}{Chevrier \emph{et al.}, 2018}). So, typically \(K = 1+3\) or \(K = 1+4\).

Experimentally, we only measure a sample from the distribution of \(Y_i\). The probabilities \(\pi_k\) and true distributions \(P(Y_i = y \mid Z_i = k)\) are unobserved, and we need to estimate them from data.
In many applications, the mixture components are \textcolor{red}{modeled to be} in a parametric family, for example, the negative binomial distribution.
As spillover correction is a pre-processing step followed by downstream analyses, choosing the wrong model can introduce biases in the next analysis step. To mitigate such biases, we propose to fit nonparametric mixture components. We make two assumptions that render the components and mixture probabilities identifiable:

\begin{itemize}
\item
  \phantomsection\label{assumption1}
  (A1) Spillover distributions are the same in bead and real experiments.

  The distribution of \(Y_i \mid Z_i = k\) for all \(k > 1\) is the same in beads and real cells. This assumption allows us to learn the spillover distributions of \(Y_i \mid Z_i = k\) for all \(k > 1\) from experiments with beads, and transfer them to the experiment with real cells. This assumption relies on high-quality single-stained bead experiments that measure spillover in the same range as the target biological experiment. In other words, a high-quality bead experiment for our method works best if the distribution of bead cells is similar to the distribution of real cells.
\item
  \phantomsection\label{assumption2}
  (A2) For each cell \(i\), the observed count \(Y_i\) can only be due to one distribution.

  This assumption is already implied by the statement of the mixture model. It allows us to calculate the spillover probability for a given count \(Y_i = y\) from the posterior probability that it arises through spillover from markers \(k > 1\),
  \[
  P(\text{spillover} \mid Y_i = y) = P(Z_i > 1 \mid Y_i = y) = 
  1 - P(Z_i = 1 \mid Y_i = y) = 
  1 - \frac{\pi_1 \, P(Y_i = y \mid Z_i = 1)}{P(Y_i = y)}.
  \]
  To parse this calculation, recall that in mixture models the \(\pi_1\) is the prior probability, \(P(Y_i = y \mid Z_i = 1)\) is the conditional probability given the mixture component, and the denominator \(P(Y_i = y)\) is the marginal distribution. Applying Bayes rule leads to the posterior probability.
\end{itemize}

\subsection{Estimation of Spillover Probability}\label{estimation-of-spillover-probability}

We propose a two step procedure for estimating the spillover probability. In step 1, we estimate mixture components and mixture probabilities. We refine these estimates using the EM algorithm (\citeproc{ref-dempster1977maximum}{Dempster \emph{et al.}, 1977}). In step 2, we use these probability estimates to assign counts to spillover or signal.

We denote the \(n \times K\) count matrix as \(\mathbf{Y} = (y_{ik})\) with real cells in the first column and beads in columns two and higher. To simplify mathematical notation but without loss of generality, we assume that the number of
\textcolor{red}{events}
from real and bead experiments have the same \(n\). In practice, the number of
\textcolor{red}{events}
from bead experiments is much smaller than from real experiments. The \(k\)th column of \(\mathbf{Y}\) contains marker counts for the \(k\)th spillover marker, which represents the empirical spillover distribution of marker \(k\) into the target marker, that is, the marker in the first column of \(\mathbf{Y}\).

\subsubsection{EM Algorithm}\label{em-algorithm}

\begin{itemize}
\item
  Initialization: For the mixture probability vector, we assign probability \(0.9\) to the the target marker and divide the probability \(0.1\) among the spillover markers,
  \[
  \hat{\pi}_{1} = 0.9 \text{ and } \hat{\pi}_i = 0.1/(K-1) \text{ for all } i > 1.
  \]
  The procedure is not sensitive to the choice of the initial mixture probability vector and other initializations are possible but may be slower to converge. Then, we initialize the \(k\)th mixture component using \textcolor{red}{its probability mass function (PMF) after smoothing and normalizing, $\widehat{P}(Y_i = y \mid Z_i = k)$. We smooth the PMF using kernel density estimation implemented in R function \texttt{density} with the default option for selecting the bandwith of a Gaussian kernel.}
\item
  E-step: We evaluate the posterior probability of a count \(y\) belonging to component \(k\) (that is, originating from marker \(k\)),
  \[
  \widehat{P}\left(Z_i = k \mid Y_i = y \right) = 
  \frac
  { \hat{\pi}_k \, \widehat{P}(Y_i = y \mid Z_i = k) }
  { \sum_{k' = 1}^K \hat{\pi}_{k'} \, \widehat{P}(Y_i = y \mid Z_i = k') }.
  \]
\item
  M-step: We estimate the new mixture probability vector from posterior probabilities,
  \[
  \hat{\pi}_k = 
  \frac{1}{n} \sum_{i = 1}^n \widehat{P}\left(Z_i = k \mid Y_i = y \right),
  \]
  and estimate the new target marker distribution \textcolor{red}{by smoothing and normalizing. Here, we use the R function \texttt{density} again}, but weight each observation according to their posterior probabilities, \(\widehat{P} \left(Z_i = 1 \mid Y_i = y \right)\). We only update the target marker, \(\widehat{P}(Y_i = y \mid Z_i = 1)\), and keep the other bead distributions, \(\widehat{P}(Y_i = y \mid Z_i = k)\) for all \(k > 1\), fixed at their initial value.
\end{itemize}

To refine our estimates, we iterate over the E and M-steps until estimates stabilize. We stop iterating when \(\hat{\pi}_1\) changes less than \(10^{-5}\) from the previous iteration. The final output is the spillover probability curve with estimates at discrete points in the support of \(Y_i\),
\[
\widehat{P}(\text{spillover} \mid Y_i = y) = 1 - \widehat{P}(Z_i = 1 \mid Y_i = y).
\]

We rely on assumption \hyperref[assumption1]{(A1)} to justify updating only the distribution of the target marker. We rely on assumption \hyperref[assumption2]{(A2)} to justify calculating the spillover probability from the mixture model. We refer to Appendix \ref{em-algorithm-example} for a step-by-step example of our EM algorithm.

\subsubsection{Spillover Decision}\label{spillover-decision}

To perform spillover compensation, we draw from a Bernoulli distribution with the spillover probability as parameter to decide whether or not to assign a given count to spillover. \textcolor{red}{We set counts designated to spillover to a user-specified value. We recommend a value of zero to maintain the overall cellular composition of the sample or a value such as \texttt{NA} or $-1$ to mark them explicitly as spillover for downstream processing.}

\subsection{\texorpdfstring{Baseline Method \texttt{spillR\ (naive)}}{Baseline Method spillR (naive)}}\label{baseline-method-spillr-naive}

\textcolor{red}{
We compare our mixture method to a naive baseline method that considers only the bead distributions. Similarly to our standard \texttt{spillR} method, we estimate the bead PMF of each bead $k$ with the kernel density estimator \texttt{density}, $\widehat{P}(Y_i | Z_i = k)$. Then, for all count values $y$ in the range of the bead counts, we separately normalize the PMF at each value $Y_i = y$ and calculate the spillover probability as, 
$$
P(Z_i = k \mid Y_i = y) = 1 - \frac{\widehat{P}(Y_i | Z_i = k)}{\sum_{k'}^K \widehat{P}(Y_i | Z_i = k)}.
$$
The spillover decision is the same as in our standard \texttt{spillR} method. This is a computationally efficient and simple baseline that, in effect, assigns counts to the marker with the highest density at the count value in the corresponding bead experiment.
}

\section{Results}\label{results}

We first evaluate our new method \texttt{spillR} on simulated datasets. We probe our method to experimentally find its shortcomings. Then, we compare \texttt{spillR} to the non-negative least squares method implemented in the R package \texttt{CATALYST} on real and \textcolor{red}{semi-simulated} data from the same package. All experiments and plots can be reproduced by compiling the R markdown file \texttt{spillR\_paper.Rmd}\footnote{\url{https://github.com/ChristofSeiler/spillR_paper}}.

\subsection{Simulated Data}\label{simulated-data}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{spillr_paper_files/figure-latex/simulated-experiments-plot-1} 

}

\caption{Three experiments testing our assumptions and sensitivity to bimodal bead distribution. For each experiment the top row are mean values over the entire range of the experimental setups. \textcolor{red}{The mean values for \texttt{spillR} are computed with \texttt{NA} imputation for spillover counts, so the mean is identical to the true mean without spillover if all spillover counts are correctly identified as such.} The bottom row are density plots for three parameter settings to illustrate the generated distributions. $Y$ is the distribution with spillover. $Y \mid Z = 1$ is the distribution without spillover. $Y \mid Z = 2$ is the spillover. mean($Y$) is the average of the distribution with spillover. mean($Y \mid Z = 1$) is the average count without spillover. \texttt{spillR} mean($Y$) is the average count after correcting $Y$.}\label{fig:simulated-experiments-plot}
\end{figure}

We choose three different experiments to test \texttt{spillR} against different bead and real cell distributions. We explore a wide range of possible parameter settings. Figure \ref{fig:simulated-experiments-plot} has three panels, each representing one experimental setup. The first two panels test our assumptions \hyperref[assumption1]{(A1)} and \hyperref[assumption2]{(A2)}. The third panel tests sensitivity of \texttt{spillR} to bimodal bead distributions. For all three experiments, we model counts using a Poisson distribution with parameter \(\lambda\). We simulate 10,000 real cells with \(\lambda = 200\), and 1,000 beads with \(\lambda = 70\), and a spillover probability of \(0.5\). The bead data are an independent copy of the true spillover. The other parameters and statistical dependencies are specific to each experiment. The details of the generative models are given in Appendix \ref{generative-models}. We repeat each simulation 20 times and report averages over the 20 replications.

Each panel of Figure \ref{fig:simulated-experiments-plot} has two rows of plots. The plot in the first row represents the summary of the means for each experimental setup as a function of their respective parameter \(\tau\). This parameter has a different meaning in each setup. To visualize the different experiments, we summarize the full distributions with the true simulated signal mean (black), the uncorrected mean (orange), and the \texttt{spillR} corrected mean (green). Plots on the second row illustrate the simulated data distributions for three selected parameters \(\tau\) picked from the experimental setup. The yellow density curve shows the observed counts \(Y\). The black density curve shows the distribution of target cell counts. The blue density curve shows the distribution of spillover counts. The goal of the experiment is to estimate the mean of the black density as accurately as possible from the yellow density curve, which represents the data \(Y\) we would observe in practice. We simulate this data using the models in Appendix \ref{generative-models}.

In the first experiment (panel A), we shift the spillover in the beads experiment away from the true spillover to probe \hyperref[assumption1]{(A1)}. We test a range of bead shifts from no shift at \(\tau = 0\) to \textcolor{red}{$\tau = -10$. At $\tau = -10$,} the measured spillover (the first mode of the yellow density) is shifted away from the actual spillover (the blue density), causing both the observed and compensated mean to be lower than the true mean. This may be the case in a low-quality bead experiment. As \(\tau\) gets closer to zero, the first mode of the yellow density moves towards the blue density (as may be the case in a higher quality bead experiment), and the compensated signal moves closer to the true mean.

In the second experiment (panel B), we mix target and spillover to explore the robustness of our method with respect to our second assumption \hyperref[assumption2]{(A2)}. One way to think about this is that the mixture is a form of model misspecification. Our mixture model is undercomplete, which means that there are more true mixture components than we observe in the beads experiment. If \(\tau = 0\), then assumption \hyperref[assumption2]{(A2)} is correct, but for \(\tau = 0.5\) the assumption \hyperref[assumption2]{(A2)} is maximally violated. The true mean decrease with increasing \(\tau\).
\textcolor{red}{\texttt{spillR} compensates well as long as $\tau$ is close to zero, but deviates from the true mean with increasing $\tau$. As the spillover distribution becomes more similar to the target marker distribution, the mean of the \texttt{spillR} flips to the mean of the observed data at $\tau \approx 0.25$, until}
at \(\tau = 0.5\) all three distributions and their means are the same.

In the third experiment (panel C), we model spillover with a bimodal distribution. Here \(\tau\) is the mixing probability of the two modes. The locations of the two spillover modes are fixed. If \(\tau = 0\) or \(\tau = 1\), then spillover is unimodal. If \(\tau = 0.5\), the first mode of the bimodal beads distribution is left to the signal mode, and the second mode is to the right. The corrected mean is closer to the true mean than the uncorrected mean across the test range.

\subsection{Real Data}\label{real-data}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{spillr_paper_files/figure-latex/spillr-vignette-1} 

}

\caption{Comparison of compensation methods and uncorrected counts on real data. Counts are arcsinh transformed with cofactor of five (\protect\hyperlink{ref-bendall2011single}{Bendall \emph{et al.}, 2011}).}\label{fig:spillr-vignette}
\end{figure}

We compare our methods to \texttt{CATALYST} on one of the example datasets in the \texttt{CATALYST} package. The dataset consists of an experiment with real cells and corresponding single-stained bead experiments. The experiment on real cells has 5,000 peripheral blood mononuclear cells from healthy donors measured on 39 channels. The experiment on beads has 10,000 cells measured on 36 channels with the number of beads per metal label ranging from 112 to 241.

In Figure \ref{fig:spillr-vignette}, we show the comparison of our methods to \texttt{CATALYST} on the same markers as their original paper (\citeproc{ref-catalyst}{Chevrier \emph{et al.}, 2018}) in their Figure 3B. In the original experiment, they conjugate the three proteins CD3, CD8, and HLA-DR with two different metal labels.
\textcolor{red}{
For example, they conjugate CD8 with Yb174Di (Yb is the metal and the number indicates the number of nucleons of the isotope) and La139Di. 
As in their plot, our columns correspond to the different metal labels.
Following their set-up, we show the three target proteins on the vertical axis.
On the horizontal axis we show the spillover markers; we show CD3 in row one, and HLA-ABC in row two and three.
}
We visualize the joint distributions using two-dimensional histograms.

In all six panels (A--F), we observe that \texttt{spillR} compensates most strongly in the low counts. In panel C, CD3 (Yb173Di) against HLA-ABC (Yb172Di), \texttt{CATALYST} can be seen to compensate strongly in the middle range. It removes the spherical pattern that shows correlation between the two markers. \texttt{spillR} preserves this correlation structure and only masks out the lower counts of CD3 (Yb173Di). This highlights a key difference between \texttt{spillR} and \texttt{CATALYST}: \texttt{spillR} \textcolor{red}{identifies counts that may arise from spillover and replaces them with a user-specified value (e.g. 0, \texttt{NA}, or -1), whereas `CATALYST` shrinks counts across the entire range to compensate for spillover.}
\textcolor{red}{
\texttt{spillR (naive)} compensates most aggressively, assigning most counts outside the target marker bead distribution to spillover.}

\textcolor{red}{
In Panels D and F we can see that \texttt{CATALYST} performs no visible compensation. For the same panels our \texttt{spillR} methods compensate strongly. Our diagnostic plots using function \texttt{plotDiagnostics} in \texttt{spillR} give some indication on why our method compensates that strongly: The original experiment is designed such that we expect no spillover in the channels on the vertical axis, but our diagnostic plots show that the bead distribution of at least one spillover marker---as identified by the spillover matrix in \texttt{CATALYST}---overlaps with the first mode in the distribution of real cells. Thus, the strong compensation by \texttt{spillR} is consistent with our assumption (A1). The results of \texttt{spillR (naive)} fit with this explanation as it completely removes all counts in that area, which occurs when there is only spillover and no signal from the target marker.
}

The color code of the two-dimensional histograms indicates the absolute number of cells that fall into one hexagon bin. The uncorrected and \texttt{spillR} corrected histograms can contain different absolute numbers of cells,
\textcolor{red}{
even for identical distributions due to a rounding step in \texttt{spillR} that converts raw counts to integers. Raw mass cytometry data may not be true count data because the proprietary post-processing of the manufacturer often performs a randomization step when exporting the data.
}
The uncorrected counts do not undergo this pre-processing step. \texttt{CATALYST} does not perform this pre-processing step. This also explains the different patterns in panel B. \texttt{spillR} has horizontal stripes that correspond to non-integer values not in the support of the distribution for \texttt{spillR}.
\textcolor{red}{
We leave the decision to apply re-randomization of the count data for downstream analysis up to the user. Our rational is that the user should see the differences in this pre-processing step and how it propagates to the results.
}

\textcolor{red}{
The average computation time with 100 replications on an Apple M1 with 8 cores and 16 GB of RAM is $10.6$ seconds for \texttt{spillR}, $0.43$ seconds for \texttt{CATALYST}, and $0.45$ seconds for \texttt{spillR (naive)}. The computational costs scale linearly in the number of cells and number of spillover markers. This allows for processing large-scale datasets.
}

\subsection{Semi-Simulated Data}\label{semi-simulated-data}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{spillr_paper_files/figure-latex/semi-simulated-plot-1} 

}

\caption{Comparison of compensation methods and uncorrected counts on semi-synthetic data   extcolor{red}{( exttt{spillR} and   exttt{spillR (naive)} are set to impute spillover values with $0$)}. The vertical dashed line helps to interpret the spillover correction. It indicates the     extcolor{red}{original mode of the bead distribution of Yb172Di at 2.725, before it overwriting it with the first peak of the real observations of Yb172Di}. Counts are arcsinh transformed with cofactor of five (\protect\hyperlink{ref-bendall2011single}{Bendall \emph{et al.}, 2011}).}\label{fig:semi-simulated-plot}
\end{figure}

\textcolor{red}{
We compare \texttt{spillR} and \texttt{CATALYST} on semi-simulated data. The goal is to elucidate differences between \texttt{spillR} and \texttt{CATALYST}, and to evaluate the performance of \texttt{spillR} if more than one marker spills into the target marker. We create semi-simulated datasets by overwriting the beads distribution for the target marker CD3 (Yb173Di). We consider the first mode of the count distribution of CD3 (Yb173Di) observed in real cells, that is, the counts from $1.44$ to $4.79$ on the transformed scale. We overwrite the beads distribution and shift counts in this range (mostly corresponding to Yb172Di) by three different values: no shift is $0$, subtracting $0.47$ on the transformed scale, and subtracting $0.94$ on the transformed scale. We further subsample without replacement from this new bead distribution to keep the same number of beads as in the original dataset. Figure \ref{fig:semi-simulated-plot} shows the three different beads experiment datasets in row A and the resulting compensations in row B.
}

\textcolor{red}{
In the first column of Figure \ref{fig:semi-simulated-plot}, the bead distributions are equal to the original dataset from Figure \ref{fig:method-example} except Yb172Di is now perfectly aligned with the first mode of the distribution of real cells (red curve in row B). In the second and third column, we shift the bead distribution of Yb172Di by $0.47$ and $0.94$. All three methods correctly compensate the spillover mode when no shift is present (first column). \texttt{CATALYST} and \texttt{spillR (naive)} compensates more aggressively in the medium shift cases (second column), while \texttt{spillR} is more moderate and compensates only the left hand tail of the spillover mode. For a shift of $0.94$ (third column), the three methods differ: \texttt{CATALYST} shrinks counts towards zero, shifting the entire spillover towards zero, \texttt{spillR} compensates lightly on the left hand tail, and \texttt{spillR (naive)} compensates aggressively leaving only a small right hand tail. This experiment illustrates how \texttt{spillR} compensates most strongly for counts that can be attributed to spillover following the distribution observed in the beads experiment.
}

\section{Discussion}\label{discussion}

\textcolor{red}{The sensitivity analysis in Section 3.1 illustrates the performance of \texttt{spillR} when our assumptions are violated.}
The experiment for \hyperref[assumption1]{(A1)} shows that the mean count after \texttt{spillR} correction is closer to the true mean over a wide range of bead shifts. This indicates that our method can perform well even if the bead experiments are imperfect. If the difference between distributions of beads and real cells is large, then one option is to rerun the bead experiments to reduce this gap. The experiment for \hyperref[assumption2]{(A2)} shows that our method is also robust to model misspecification. Additionally, misspecification can be addressed by adding all channels if necessary. The increase in computational cost when adding channels is relatively minor as our method scales linearly in the number of spillover markers. The experiment on bimodal bead distributions shows that the mean count after correction is still closer to the true mean even with bimodal bead distributions, even if the spillover is larger than the true signal.

In our comparison with \texttt{CATALYST} on \textcolor{red}{real data (Section 3.2) and semi-simulated data (Section 3.3)}, we observe the effect of the two different correction strategies. \texttt{CATALYST} essentially shrinks counts towards zero by minimizing a non-negative least squares objective. It assumes that spillover is linear up to counts of 5,000. The applied shrinkage is the same for low counts (e.g., below 10) and high counts (e.g., more than 100). By contrast, \texttt{spillR} does not require linearity of the spillover, but assumes that the distribution on the beads experiment carries over to the real cells experiment. In other words, the optimal beads experiment has the same peaks as the real cells experiment.

If counts are in the spillover range (which mostly applies to low counts), they are corrected strongly and set to \textcolor{red}{a user-specified imputation value}. If counts are not in the spillover range, they are left unchanged.
\textcolor{red}{Among the unchanged counts,} correlations between markers are preserved. The marker correlation between HLA-ABC (Yb172Di) and CD3 (Yb173Di) shown in the first column of Figure \ref{fig:spillr-vignette} illustrates this point. \texttt{CATALYST} removes the positively correlated count concentration, whereas \texttt{spillR} keeps it. Compensation methods should try to remove spillover while keeping potentially biologically meaningful signal for unbiased downstream analyses. In this example, further experiments on the correlation structure between these markers would be necessary to resolve the discrepancy between the two methods. This is an important point as discovering correlations between markers can lead to the discovery of new clusters or signaling networks.

\textcolor{red}{
Our baseline method, \texttt{spillR (naive)}, illustrates the behavior of more aggressive compensation by considering only the bead distribution. If our baseline method compensates aggressively in a certain range, this is because there are only non-target beads observed in that range. This approach highlights the allure and pitfalls of overcorrecting. While in Figure 1 it may seem that \texttt{spillR (naive)} removes all spillover by removing the first mode (Just like \texttt{CATALYST}), a closer inspection reveals that discrepancies between the bead spillover distribution and the first mode of the real cell distribution are not taken into account by either method, but do reflect in the compensation of \texttt{spillR}. A similar pattern can be seen in panels A, B, and C of Figure 3. This behavior reflects our assumption (A1) and highlights the role of bead experiments in the compensation process performed by \texttt{spillR}.
}

An additional advantage of our method is the diagnostic plot of the spillover probability curve. We can judge if the curve makes sense by comparing it to the observed count and bead distributions. Methods based on non-negative least squares \textcolor{red}{such as \texttt{CATALYST}} are harder to diagnose as they minimize a cost function with no clear biological interpretation. In our view, one of the biggest strengths of our current method is that it does not assume a specific parametric model for count data. We believe that this is crucial because spillover compensation precedes many downstream analysis steps, and avoiding the introduction of bias is thus our top priority.

\textcolor{red}{
For future work, we plan to apply our methodology to imaging mass cytometry (Angeloet al., 2014; Giesenet al., 2014; Bodenmiller, 2016). The basic method can be applied as is, but it will be beneficial to incorporate a spatial regularization term that enforces neighboring spillover to be similar to one another.
}

\section*{Acknowledgments}\label{acknowledgments}
\addcontentsline{toc}{section}{Acknowledgments}

We thank EuroBioC2022 for awarding Marco Guazzini a travel award to present a preliminary version of \texttt{spillR} in Heidelberg. We thank Antoine Chambaz for his feedback on an earlier draft that substantially improved the paper. Alexander G. Reisach received funding from the European Union's Horizon 2020 research and innovation program under the Marie Sk\l{}odowska-Curie grant agreement No 945 nbins \euflag.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-sp-c}
Bagwell,C.B. and Adams,E.G. (1993) Fluorescence spectral overlap compensation for any number of flow cytometry parameters. \emph{Annals of the New York Academy of Sciences}, \textbf{677}, 167--184.

\bibitem[\citeproctext]{ref-bandura2009mass}
Bandura,D.R. \emph{et al.} (2009) Mass cytometry: Technique for real time single cell multitarget immunoassay based on inductively coupled plasma time-of-flight mass spectrometry. \emph{Analytical Chemistry}, \textbf{81}, 6813--6822.

\bibitem[\citeproctext]{ref-bendall2011single}
Bendall,S.C. \emph{et al.} (2011) Single-cell mass cytometry of differential immune and drug responses across a human hematopoietic continuum. \emph{Science}, \textbf{332}, 687--696.

\bibitem[\citeproctext]{ref-catalyst}
Chevrier,S. \emph{et al.} (2018) Compensation of signal spillover in suspension and imaging mass cytometry. \emph{Cell Systems}, \textbf{6}, 612--620.e5.

\bibitem[\citeproctext]{ref-dempster1977maximum}
Dempster,A.P. \emph{et al.} (1977) Maximum likelihood from incomplete data via the {EM} algorithm. \emph{Journal of the Royal Statistical Society: Series B (Methodological)}, \textbf{39}, 1--22.

\bibitem[\citeproctext]{ref-lun2017influence}
Lun,X.-K. \emph{et al.} (2017) Influence of node abundance on signaling network state and dynamics analyzed by mass cytometry. \emph{Nature Biotechnology}, \textbf{35}, 164--172.

\bibitem[\citeproctext]{ref-scater}
McCarthy,D.J. \emph{et al.} (2017) Scater: Pre-processing, quality control, normalization and visualization of single-cell {RNA}-seq data in {R}. \emph{Bioinformatics}, \textbf{33}, 1179--1186.

\bibitem[\citeproctext]{ref-mclachlan2019finite}
McLachlan,G.J. \emph{et al.} (2019) Finite mixture models. \emph{Annual Review of Statistics and Its Application}, \textbf{6}, 355--378.

\bibitem[\citeproctext]{ref-miao2021ab}
Miao,Q. \emph{et al.} (2021) Ab initio spillover compensation in mass cytometry data. \emph{Cytometry Part A}, \textbf{99}, 899--909.

\bibitem[\citeproctext]{ref-novo2013generalized}
Novo,D. \emph{et al.} (2013) Generalized unmixing model for multispectral flow cytometry utilizing nonsquare compensation matrices. \emph{Cytometry Part A}, \textbf{83}, 508--520.

\bibitem[\citeproctext]{ref-seiler2021cytoglmm}
Seiler,C. \emph{et al.} (2021) CytoGLMM: Conditional differential analysis for flow and mass cytometry experiments. \emph{BMC Bioinformatics}, \textbf{22}, 1--14.

\bibitem[\citeproctext]{ref-takahashi2017mass}
Takahashi,C. \emph{et al.} (2017) Mass cytometry panel optimization through the designed distribution of signal interference. \emph{Cytometry Part A}, \textbf{91}, 39--47.

\bibitem[\citeproctext]{ref-diffcyt}
Weber,L.M. \emph{et al.} (2019) {d}iffcyt: Differential discovery in high-dimensional cytometry via high-resolution clustering. \emph{Communications Biology}, \textbf{2}, 1--11.

\end{CSLReferences}

\newpage

\appendix


\section{EM Algorithm Example}\label{em-algorithm-example}

Here we illustrate the procedure using a numerical example that includes one target and one spillover marker. We have one data matrix \(\mathbf{Y}\) that contains real cell counts recorded for marker 1 (column 1) and the bead counts for marker 1 when the true marker was marker 2 (column 2). In practice, \(\mathbf{Y}\) is usually a matrix with more than two columns representing multiple spillover markers. The index \(i\) is a specific cell in beads and real cells experiment, respectively. Let's assume the following counts,
\[
\mathbf{Y} = (y_{ij}) = 
\begin{bmatrix}
3 & 2 \\ 
5 & 3 \\ 
17 & 2 \\ 
3   \\ 
17 \\ 
2 
\end{bmatrix}.
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{target    }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{17}\NormalTok{,  }\DecValTok{3}\NormalTok{,  }\DecValTok{17}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{spillover }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{,  }\DecValTok{2}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{, }\ConstantTok{NA}\NormalTok{)}
\NormalTok{Y }\OtherTok{=}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{bind\_cols}\NormalTok{(}\AttributeTok{target =}\NormalTok{ target, }\AttributeTok{spillover =}\NormalTok{ spillover)}
\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   target spillover
##    <dbl>     <dbl>
## 1      3         2
## 2      5         3
## 3     17         2
## 4      3        NA
## 5     17        NA
## 6      2        NA
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Initialization: We initialize our EM algorithm by estimating the conditional probability of observing \(y\) given that it belongs to the target marker, and another conditional probability given that it belongs to the spillover marker.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_min }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(Y}\SpecialCharTok{$}\NormalTok{target)}
\NormalTok{y\_max }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(Y}\SpecialCharTok{$}\NormalTok{target)}
\NormalTok{y\_support }\OtherTok{\textless{}{-}}\NormalTok{ y\_min}\SpecialCharTok{:}\NormalTok{y\_max}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{density}\NormalTok{(Y}\SpecialCharTok{$}\NormalTok{target, }\AttributeTok{from =}\NormalTok{ y\_min, }\AttributeTok{to =}\NormalTok{ y\_max)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{density}\NormalTok{(Y}\SpecialCharTok{$}\NormalTok{spillover, }\AttributeTok{from =}\NormalTok{ y\_min, }\AttributeTok{to =}\NormalTok{ y\_max, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{f1 }\OtherTok{\textless{}{-}} \FunctionTok{approxfun}\NormalTok{(fit1}\SpecialCharTok{$}\NormalTok{x, fit1}\SpecialCharTok{$}\NormalTok{y)}
\NormalTok{f2 }\OtherTok{\textless{}{-}} \FunctionTok{approxfun}\NormalTok{(fit2}\SpecialCharTok{$}\NormalTok{x, fit2}\SpecialCharTok{$}\NormalTok{y)}
\NormalTok{P\_Y1 }\OtherTok{\textless{}{-}} \FunctionTok{f1}\NormalTok{(y\_support)}
\NormalTok{P\_Y1 }\OtherTok{\textless{}{-}}\NormalTok{ P\_Y1 }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(P\_Y1)}
\NormalTok{P\_Y2 }\OtherTok{\textless{}{-}} \FunctionTok{f2}\NormalTok{(y\_support)}
\NormalTok{P\_Y2 }\OtherTok{\textless{}{-}}\NormalTok{ P\_Y2 }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(P\_Y2)}
\NormalTok{P\_YZ }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{bind\_cols}\NormalTok{(}\AttributeTok{P\_Y1 =}\NormalTok{ P\_Y1, }\AttributeTok{P\_Y2 =}\NormalTok{ P\_Y2)}
\end{Highlighting}
\end{Shaded}

We initialize the mixture probabilities with the discrete uniform.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.9}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now, we update these initial values using the E and M-steps.

\begin{itemize}
\tightlist
\item
  E-step: Calculate the posterior probability for the true marker, and the spillover marker.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{P\_ZY }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(P\_YZ, }
                      \AttributeTok{P\_Y1 =}\NormalTok{ pi[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ P\_Y1, }
                      \AttributeTok{P\_Y2 =}\NormalTok{ pi[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ P\_Y2)}
\NormalTok{P\_ZY }\OtherTok{\textless{}{-}}\NormalTok{ P\_ZY }\SpecialCharTok{/} \FunctionTok{rowSums}\NormalTok{(P\_ZY)}
\NormalTok{P\_ZY }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{bind\_cols}\NormalTok{(}\AttributeTok{target =}\NormalTok{ y\_support, P\_ZY)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  M-step: Update the mixing probability vector,
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(Y)}
\NormalTok{YP }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{left\_join}\NormalTok{(Y, P\_ZY, }\AttributeTok{by =} \StringTok{"target"}\NormalTok{)}
\NormalTok{YP}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
##   target spillover  P_Y1     P_Y2
##    <dbl>     <dbl> <dbl>    <dbl>
## 1      3         2 0.717 2.83e- 1
## 2      5         3 1.00  5.70e-13
## 3     17         2 1     9.29e-17
## 4      3        NA 0.717 2.83e- 1
## 5     17        NA 1     9.29e-17
## 6      2        NA 0.550 4.50e- 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{sum}\NormalTok{(YP}\SpecialCharTok{$}\NormalTok{P\_Y1) }\SpecialCharTok{/}\NormalTok{ n, }\FunctionTok{sum}\NormalTok{(YP}\SpecialCharTok{$}\NormalTok{P\_Y2) }\SpecialCharTok{/}\NormalTok{ n)}
\NormalTok{pi}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8307516 0.1692484
\end{verbatim}

and re-estimate the distribution for the target marker using the posterior probabilities as weights, keep the non-target marker at its initial value,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{density}\NormalTok{(Y}\SpecialCharTok{$}\NormalTok{target, }\AttributeTok{from =}\NormalTok{ y\_min, }\AttributeTok{to =}\NormalTok{ y\_max, }\AttributeTok{weights =}\NormalTok{ YP}\SpecialCharTok{$}\NormalTok{P\_Y1)}
\NormalTok{f1 }\OtherTok{\textless{}{-}} \FunctionTok{approxfun}\NormalTok{(fit1}\SpecialCharTok{$}\NormalTok{x, fit1}\SpecialCharTok{$}\NormalTok{y)}
\NormalTok{P\_Y1 }\OtherTok{\textless{}{-}} \FunctionTok{f1}\NormalTok{(y\_support)}
\NormalTok{P\_Y1 }\OtherTok{\textless{}{-}}\NormalTok{ P\_Y1 }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(P\_Y1)}
\NormalTok{P\_YZ }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(}\AttributeTok{P\_Y1 =}\NormalTok{ P\_Y1, }\AttributeTok{P\_Y2 =}\NormalTok{ P\_Y2)}
\end{Highlighting}
\end{Shaded}

and calculate the spillover probability estimate,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{P\_ZY }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(P\_YZ, }
                      \AttributeTok{P\_Y1 =}\NormalTok{ pi[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ P\_Y1, }
                      \AttributeTok{P\_Y2 =}\NormalTok{ pi[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ P\_Y2)}
\NormalTok{P\_ZY }\OtherTok{\textless{}{-}}\NormalTok{ P\_ZY }\SpecialCharTok{/} \FunctionTok{rowSums}\NormalTok{(P\_ZY)}
\NormalTok{P\_ZY }\OtherTok{\textless{}{-}}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{bind\_cols}\NormalTok{(}\AttributeTok{target =}\NormalTok{ y\_support, P\_ZY)}
\NormalTok{P\_ZY }\SpecialCharTok{|\textgreater{}}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_spillover =} \FunctionTok{round}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ P\_Y1, }\AttributeTok{digits =} \DecValTok{3}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(target, p\_spillover) }\SpecialCharTok{|\textgreater{}}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(target }\SpecialCharTok{\%in\%} \FunctionTok{unique}\NormalTok{(Y}\SpecialCharTok{$}\NormalTok{target))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   target p_spillover
## 1      2       0.631
## 2      3       0.449
## 3      5       0.000
## 4     17       0.000
\end{verbatim}

This is the result after one iteration.

\section{Generative Models}\label{generative-models}

\subsection*{Bead Shift}\label{bead-shift}
\addcontentsline{toc}{subsection}{Bead Shift}

Generative model for real cells \(Y\) of this experiment:
\[
\begin{aligned}
I              & \sim \text{Bernoulli}(0.1)                            & \qquad \text{(spillover indicator)} \\
Z              & = I + 1                                               & \qquad \text{(channel number)} \\
(Y \mid Z = 1) & \sim \text{Poisson}(200)                              & \qquad \text{(target component)} \\
(Y \mid Z = 2) & \sim \text{Poisson}(70+\tau)                          & \qquad \text{(spillover component with shift)} \\
Y              & = (1-I) \cdot (Y \mid Z = 1) + I \cdot (Y \mid Z = 2) & \qquad \text{(mixture)}.
\end{aligned}
\]
The generative model for beads is an independent copy of the unshifted \(Y \mid Z = 2\) at \(\tau = 0\).

\subsection*{Model Misspecification}\label{model-misspecification}
\addcontentsline{toc}{subsection}{Model Misspecification}

Generative model for real cells \(Y\) of this experiment:
\[
\begin{aligned}
I              & \sim \text{Bernoulli}(0.1)                            & \qquad \text{(spillover indicator)} \\
Z              & = I + 1                                               & \qquad \text{(channel number)} \\
T              & \sim \text{Poisson}(200)                              & \qquad \text{(target)} \\
S              & \sim \text{Poisson}(70)                               & \qquad \text{(spillover)} \\
M              & \sim \text{Bernoulli}(\tau)                           & \qquad \text{(misspecification indicator)} \\
(Y \mid Z = 1) & = (1-M) \cdot T + M \cdot S                           & \qquad \text{(target mixture component)} \\
(Y \mid Z = 2) & = (1-M) \cdot S + M \cdot T                           & \qquad \text{(spillover mixture component)} \\
Y              & = (1-I) \cdot (Y \mid Z = 1) + I \cdot (Y \mid Z = 2) & \qquad \text{(mixture)}
\end{aligned}
\]
The generative model for beads is an independent copy of \(Y \mid Z = 2\).

\subsection*{Bimodal Spillover}\label{bimodal-spillover}
\addcontentsline{toc}{subsection}{Bimodal Spillover}

Generative model for real cells \(Y\) of this experiment:
\[
\begin{aligned}
I               & \sim \text{Bernoulli}(0.1)                            & \qquad \text{(spillover indictor)} \\
Z               & = I + 1                                               & \qquad \text{(channel number)} \\
(Y \mid Z = 1)  & \sim \text{Poisson}(200)                              & \qquad \text{(target component)} \\
H               & \sim \text{Bernoulli}(\tau)                           & \qquad \text{(high count indicator)} \\
(S \mid H = 0)  & \sim \text{Poisson}(70)                               & \qquad \text{(low count component)} \\
(S \mid H = 1)  & \sim \text{Poisson}(330)                              & \qquad \text{(high count component)} \\
( Y \mid Z = 2) & = (1-H) \cdot (S \mid H = 0) + H \cdot (S \mid H = 1) & \qquad \text{(spillover component)} \\
Y               & = (1-I) \cdot (Y \mid Z = 1) + I \cdot (Y \mid Z = 2) & \qquad \text{(mixture)}
\end{aligned}
\]
The generative model for beads is an independent copy of \(Y \mid Z = 2\).

\end{document}
